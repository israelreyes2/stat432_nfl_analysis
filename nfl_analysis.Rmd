---
title: "Down By 4, 2nd And Goal, 26 Seconds To Go, What Play Are YOU Calling?"
author:
- Eric Jong Bum Kim (jekim3)
- Israel Reyes (ir2)
- Jihee Hwang (jhwang55)
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document: default
  pdf_document: default
subtitle: STAT 432 FA2019 - Team LRHK
abstract: Coming Soon
---

\newpage 

# Introduction

National Football League, NFL, is one of the most-loved professional sports leagues in the United States. NFL is undoubtedly the top sports league in the United States bringing in over $13 billion in revenue each year.  Football is unique in that it is almost turn-based sports. Some say that football is a chess game. Head coaches call plays and players execute them. Every coach's goal for each play is to increase their chance of winning the game the most. Coaches call plays based on a combination of experiences, time on the clock, field position, players on the field, and many more. Were the plays called by coaches make sense analytically? 

One of the most debated play calling happened in the 2015 Super Bowl. In Super Bowl XLIX (Seattle Seahawks vs. New England Patriots), Down by 4 and on 2nd and goal with 26 seconds to go,  Pete Caroll decided to pass the ball instead of running the ball. In the context of the game, Seattle Seahawks had one of the most dominant running back in the game at the time, Marshawn  Lynch, but they decided to pass the ball resulting in an interception, and New England Patriots won the Super Bowl. Many questioned, why would Seahawks pass the ball at that point in the game? This play still hunts Seahawks fans. With that, did Pete Caroll and Seattle Seahawks believe that passing play would have resulted in increasing the probability of the winning game more than a running play? Maybe we could use the statical models to make sense of such a situation. 

In an attempt to construct meaningful and effective ways for coaches to call what type of play purely rely on analytic probability, various statistical learning techniques will be applied to the NFL play-by-play data. The main goal of our study is to see if football-game related measures such as game clock situation, position on the field, and players on the field at the moment can increase the chance of winning the most for the team. In NFL, there is a measure called, winning percentage. Winning percentage measures the probability of a team winning at the given moment of the game, and since football game stop after each play, winning percentage changes after each play.  Our model will focus only on the offensive side of the ball. Ultimately, we will see if we can utilize statistical learning techniques for an offensive coordinator to call plays based on analytic. 

# Background Information On Data

The dataset was retrieved from Kaggle [^1] and originated from github [^2]. In order to provide clean, play-by-play data via open-source software package in football, a group of Carnegie Mellon University statistical researchers [^3] Maksim Horowitz, Ron Yurko, and Sam Ventura built an nflscrapR [^4] package in R which outputs datasets for individual play, player, game, and season levels accessed from the NFL [^5]. There are three versions of the data sources in Kaggle, and we will be using the most recent version (v5) for NFL Play by Play data for 2009-2018.

This package supplies freely available datasets for current and reproducible research in the statistical analysis of NFL, which has not been accessible in the past unlike other sports such as baseball, basketball, and hockey. Using the data from the package, the researchers from Carnegie Mellon also built reproducible methods for generating expected points and win probability models for the NFL [^6] which is included in the datasets.  

# Data Description

The NFL play-by-play data for season contains 257 different variables in an attempt to explain every play of the game in every game of the season. Each and every play of the game is broken down into great detail containing information on the game situation, players involved, results, and advanced football analytic metrics. Here are a few variables correlating to these.

 - Game situation : _Posteam_, _Defteam_,  _Game_date_
 - Play results : _yrd_gained_, _yrd_after_catch_
 - advanced analytic : _wpa_

To further explain WPA measure, WPA stands for win probability added. The difference between the team's win probability at the beginning of the play and at the end of the play. For the purpose of our study, we will assume that WPA measures a team's probability of winning after each offensive plays are called. We will also manipulate the data into a more concise form. 

# Data Cleaning

1. Our project will only consider the 2018 NFL season. 2018 season opened with Atlanta Falcons playing Philadelphia Eagles on 09/06/2018 and ended on 12/30/2018. We decided to focus on the 2018 season only due to the size of the data, and the ever-changing trends of the style of the game. 

2. With 257 variables, we had to narrow down our variables. There are many variables there are quite meaningless. Based on our prior knowledge of the game, we will narrow down to variables that we believe might be variables that coaches can input during the game. These include variables such as field position, game clock situations, and result of the game. these variables are subject to change as the study goes further. 

3. We will consider variables that are measured after the plays, such as the yard gained after the catch. Putting on the offensive coordinator's hat, I would assume if I run a pass plays, I expect my receiver to catch the pass and run as much as they can. Even though yards after the catch are unpredictable, if I were an offensive coordinator, I would have confidence in my receiver to gain yards after catching the pass. 

4. In our data, there are 10 different types of plays a team execute in the game. However, for the purpose of our study, we will remove the following play types for the following reasons. 

 - NA: these are game administrative play types such as the end of the quarters, end of the regulation, and 2-minute warnings. These are already considered with the game time remainning. 

 - QB_kneel: most of the time, QB will only kneel when the game result has already been decided and to run down the clock to the end of the game, so we will ignore these.

 - kickoff: In NFL games, two kickoffs always happen, once at the beginning of the 1st quarter and once more at the beginning of the 3rd quarter. However, WPA is not calculated when the initial kickoff in the 1st quarter happens, so these will be ignored. However, WPA from any other kickoffs, after scoring, is valid. 

 - no_play: no_play represents plays in which penalty has occurred. We will ignore these since an offensive coordinator will never expect their own plays to be called for a penalty. For the purpose of calling plays, penalty factors are not considered.

5. After cleaning up the variables based on our piror knowledge of the game, following variables's NAs will be replaced with following methods.

These are numerical variables, and for these NAs represented follwings and are replaced by 0:
  - Air Yards: NAs are when either running or speical team plays are called
  - Yards After Catch: NAs are when either running or speical team players are called or 0 yard gains after catch
  - Kick Distance: Non-speical team plays are called
  
We decided that replacing NAs with 0 made sense for these variables.

These are character variabls, and these NAs are replaced with "NA":
 - Pass Location
 - Run Location
 - Run Gap
 - Field Goal Result
 - Pass Length 
 
 We decided that replacing NAs with "NA" since NAs represent other type of plays are called. 

6. Variables are transformed to factor type to ensure our model will intake them accordingly. 

# Statistical Learning Task

That being said, the statistical learning task to accomplish this goal will be with the means of classification models. Given certain features of the data set like the geographical location, the length of the trip, cost and many others we will be classifying the company that corresponding trip applies to. It is immediately apparent that binary classification models are out of the question unless we would like to target a specific company to make it the positive class meanwhile the others are grouped into another classification. The problem with this however is that could potentially make the data set uneven and although there are methods to combat this problem, we would have to model depending how many unique companies are in the data set. Multi-class classification would have to be the main method for our goal with use of K-Nearest Neighbors and Random Forests along with cross validation, where we will be using 2 metrics to maximize being accuracy and sensitivity. 

# Data Loading

```{r package loading, warning = FALSE, include=FALSE}
library(dplyr)
library(tidyverse)
library(caret)
library(rsample)
library(glmnet)
```

```{r data loading, warning = FALSE}
df_2018_first = read_csv("/cloud/project/NFL_2018_first.csv") #first half data only
df_2018_second = read_csv("/cloud/project/NFL_2018_second.csv") #second half data only
df_2018 = rbind(df_2018_first, df_2018_second) #combining them both
```

## Data Cleaning

```{r variable clean up, offense only}
keep = c("posteam", "defteam", "yardline_100", "game_date", "game_seconds_remaining", "qtr", "down", "ydstogo", #game administravtive variables
         "play_type","shotgun", "no_huddle", "qb_dropback", "pass_location", #offensive game types
         "yards_gained", "pass_length", "air_yards", "yards_after_catch", #offensive pass play results
         "run_location", "run_gap", #offensive run plays
         "field_goal_result", "kick_distance", #speical teams
         "posteam_timeouts_remaining", "defteam_timeouts_remaining", #time out remainings
         "wpa") #responce variables

df_2018_reduced = subset(df_2018, select = keep)
```

```{r, checking no_plays in play type}
#no_play = subset(df_2018, df_2018$play_type == "no_play")
#head(no_play)
```

```{r, removing adminstrative playtypes}
#adminstratvie plays such as two-minute warnings will be removed
#game_warnings = sum(is.na(df_2018$play_type)) #all of the NA playtypes are either end of quaters or two-min warnings. (1429 of them)

df_2018_reduced_no_admin_plays = df_2018_reduced[complete.cases(df_2018_reduced[ , "play_type"]),] #40607 rows
```

```{r, removing qb kneels}
df_2018_reduced_no_qb_kneels = subset(df_2018_reduced_no_admin_plays, df_2018_reduced_no_admin_plays$play_type != "qb_kneel") #40247 rows
```

```{r, removing inital kickoffs}
df_2018_reduced_no_kick_off = df_2018_reduced_no_qb_kneels %>%
  subset(game_seconds_remaining != 3600 & play_type != "kickoff") #37641 rows
```

```{r clenaing up various missing wpa rows}
df_2018_cleaned = df_2018_reduced_no_kick_off[complete.cases(df_2018_reduced_no_kick_off[ , "wpa"]),]
```

```{r replacing na with 0 for numeric variables}
df_2018_cleaned$air_yards[is.na(df_2018_cleaned$air_yards)] = 0
df_2018_cleaned$yards_after_catch[is.na(df_2018_cleaned$yards_after_catch)] = 0
df_2018_cleaned$kick_distance[is.na(df_2018_cleaned$kick_distance)] = 0
```

```{r replacing NAs with characters}
df_2018_cleaned$pass_location[is.na(df_2018_cleaned$pass_location)] = "NA"
df_2018_cleaned$run_location[is.na(df_2018_cleaned$run_location)] = "NA"
df_2018_cleaned$run_gap[is.na(df_2018_cleaned$run_gap)] = "NA"
df_2018_cleaned$field_goal_result[is.na(df_2018_cleaned$field_goal_result)] = "NA"
df_2018_cleaned$pass_length[is.na(df_2018_cleaned$pass_length)] = "NA"
```

```{r variable factor type conversion}
factor_list = c("posteam", "defteam", "play_type", "pass_location", "pass_length", "run_location", "run_gap", "field_goal_result")

df_2018_cleaned[factor_list] <- lapply(df_2018_cleaned[factor_list], factor)
```

# Training Testing Data Split
```{r data split}
set.seed(1)

# test-train split
nfl_tst_trn_split = initial_split(df_2018_cleaned, prop = 0.80)
nfl_trn = training(nfl_tst_trn_split)
nfl_tst = testing(nfl_tst_trn_split)
```

# Data Modeling 

```{r calculating rmse}
calc_rmse = function(actual, predicted){
  sqrt(mean((actual - predicted)^2))
}
```

```{r ridge modeling}
# Omitting random NAs in the data
nfl_trn = na.omit(nfl_trn)
nfl_tst = na.omit(nfl_tst)

# Train data frame matrix
trn_x = model.matrix(wpa ~ ., nfl_trn)[, -1]
trn_y = nfl_trn %>%
  select(wpa) %>%
  unlist() %>%
  as.numeric()

# Test data frame matrix
tst_x = model.matrix(wpa ~., nfl_tst)[, -1]
tst_y = nfl_trn %>%
  select(wpa) %>%
  unlist() %>%
  as.numeric()

# Setting the range of lambda values
lambda_seq  = 10^seq(2, -2, by = -.1)

# Using glmnet function to build the ridge regression model
cv_fit = cv.glmnet(trn_x, trn_y, alpha = 0, lambda = lambda_seq, nfolds = 10)
plot(cv_fit)

# Best lambda value
best_lambda = cv_fit$lambda.min

# Calculating rmse 
predicted = predict(cv_fit, trn_x)

ridge_model_RMSE = calc_rmse(trn_y, predicted)
```


[^1]: [Kaggle: Detailed NFL Play-by-Play Data 2009-2018](https://www.kaggle.com/maxhorowitz/nflplaybyplay2009to2016)

[^2]: [GitHub: 'nflscrapR-data'](https://github.com/ryurko/nflscrapR-data)

[^3]: [Carnegie Mellon University: Statistics & Data Science](http://www.stat.cmu.edu)

[^4]: [GitHub: nflscrapR](https://github.com/maksimhorowitz/nflscrapR)

[^5]: [NFL: Official Website](https://www.nfl.com)

[^6]: [GitHub: nflscrapR-models](https://github.com/ryurko/nflscrapR-models)


